{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import json\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "import response_extractor\n",
    "from collections import defaultdict\n",
    "import multiprocessing as mp\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_folder = (\n",
    "    \"/mnt/pfs/zitao_team/tianqiaoliu/Project/teammates/hidden_cot/prediction\"\n",
    ")\n",
    "result_dir = prediction_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_match(predictions, references):\n",
    "    # for f1, f2 in itertools.product([float, eval], repeat=2):\n",
    "    try:\n",
    "        if abs(eval(f\"({predictions})\") - eval(f\"({references})\")) < 1e-3:\n",
    "            return True\n",
    "    except:\n",
    "        pass\n",
    "    return False\n",
    "\n",
    "\n",
    "dir_name = prediction_folder\n",
    "\n",
    "\n",
    "def unique_verify_dicts(dicts, key):\n",
    "    seen = set()\n",
    "    result = []\n",
    "    for d in dicts:\n",
    "        meta = json.loads(json.loads(d[\"meta\"])[\"meta\"])\n",
    "        if meta[\"input\"] not in seen:\n",
    "            seen.add(meta[\"input\"])\n",
    "            result.append(d)\n",
    "    return result\n",
    "\n",
    "\n",
    "def unique_dicts(dicts, key):\n",
    "    seen = set()\n",
    "    result = []\n",
    "    for d in dicts:\n",
    "        if d[key] not in seen:\n",
    "            seen.add(d[key])\n",
    "            result.append(d)\n",
    "    return result\n",
    "\n",
    "\n",
    "def unique_conversation_dicts(dicts):\n",
    "    seen = set()\n",
    "    result = []\n",
    "    for d in dicts:\n",
    "        meta = json.loads(d[\"meta\"])\n",
    "        if \"conversations\" in meta:\n",
    "            if meta[\"conversations\"][-1][\"value\"] not in seen:\n",
    "                seen.add(meta[\"conversations\"][-1][\"value\"])\n",
    "                result.append(d)\n",
    "        else:\n",
    "            if meta[\"question\"] not in seen:\n",
    "                seen.add(meta[\"question\"])\n",
    "                result.append(d)\n",
    "    return result\n",
    "\n",
    "\n",
    "def process_model(model_name, data_name):\n",
    "    # Since in this we have ckpts, we change the folder with model-name + data-name + ckpts\n",
    "    result = {}\n",
    "    model_data_folder = os.path.join(result_dir, model_name, data_name)\n",
    "    for ckpts in os.listdir(model_data_folder):\n",
    "        model_data_ckpt = os.path.join(model_data_folder, ckpts)\n",
    "        gpt_verification = [\n",
    "            json.loads(line)\n",
    "            for file in glob.glob(model_data_ckpt + \"/*add_gpt4_verification.jsonl\")\n",
    "            for line in open(file, \"r\")\n",
    "        ]\n",
    "        gpt_verification = unique_verify_dicts(gpt_verification, \"question\")\n",
    "        before = len(gpt_verification)\n",
    "        gpt_verification = [\n",
    "            line for line in gpt_verification if line.get(\"response\", None)\n",
    "        ]\n",
    "        after = len(gpt_verification)\n",
    "        if len(gpt_verification) > 0:\n",
    "            result[\"gpt4_verification\"] = {}\n",
    "            result[\"gpt4_verification\"][\"instances\"] = []\n",
    "            correct = 0\n",
    "            for line in gpt_verification:\n",
    "                new_line = {}\n",
    "                if isinstance(line[\"response\"], str):\n",
    "                    match = re.findall(\n",
    "                        r\"<answer>(.*)</answer>\",\n",
    "                        line[\"response\"].split(\"[assistant](#verification)\")[-1],\n",
    "                    )\n",
    "                else:\n",
    "                    with open(\"error.log\", \"a\") as f:\n",
    "                        f.write(f\"{line}\\n\")\n",
    "                new_line[\"correct\"] = 1 if match and match[0] == \"correct\" else 0\n",
    "                new_line[\"verification\"] = match[0] if match else None\n",
    "                result[\"gpt4_verification\"][\"instances\"].append(new_line)\n",
    "                correct += new_line[\"correct\"]\n",
    "            result[\"gpt4_verification\"][\"acc\"] = correct / len(gpt_verification)\n",
    "            result[\"gpt4_verification\"][\"count\"] = len(gpt_verification)\n",
    "            result[\"gpt4_verification\"][\"response_null_count\"] = before - after\n",
    "        if result:\n",
    "            os.makedirs(f\"metric_output/{model_name}/{ckpts}\", exist_ok=True)\n",
    "            with open(f\"metric_output/{model_name}/{ckpts}/{data_name}.json\", \"w\") as f:\n",
    "                json.dump(\n",
    "                    result, f, indent=4, separators=(\",\", \": \"), ensure_ascii=False\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [\n",
    "    \"llama2-7B-gsm8k-without-cot\",\n",
    "    \"llama2-7B-gsm8k-normal-cot\",\n",
    "    \"llama2-13B-gsm8k-without-cot\",\n",
    "    # \"HCOT_7b_mse_10_bs_128_ckpt_100\",\n",
    "    \"llama2-13B-gsm8k-normal-cot\",\n",
    "]\n",
    "others_dataset_list = [\"GSM8K\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for one_model_name in model_list:\n",
    "    for one_data_name in others_dataset_list:\n",
    "        process_model(one_model_name, one_data_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [\n",
    "    \"HCOT_7b_mse_10_bs_128_ckpt_100\",\n",
    "]\n",
    "others_dataset_list = [\"GSM8K\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for one_model_name in model_list:\n",
    "    for one_data_name in others_dataset_list:\n",
    "        process_model(one_model_name, one_data_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
